@inbook{voelker2021,
  author="Voelker, Aaron R. and Eliasmith, Chris",
  editor="Thakor, Nitish V.",
  title="Programming Neuromorphics Using the Neural Engineering Framework",
  bookTitle="Handbook of Neuroengineering",
  year="2021",
  publisher="Springer Singapore",
  address="Singapore",
  pages="1--43",
  abstract="As neuromorphic hardware begins to emerge as a viable target platform for artificial intelligence (AI) applications, there is a need for tools and software that can effectively compile a variety of AI models onto such hardware. Nengo (http://nengo.ai) is an ecosystem of software designed to fill this need with a suite of tools for creating, training, deploying, and visualizing neural networks for various hardware backends, including CPUs, GPUs, FPGAs, microcontrollers, and neuromorphic hardware. While backpropagation-based methods are powerful and fully supported in Nengo, there is also a need for frameworks that are capable of efficiently mapping dynamical systems onto such hardware while best utilizing its computational resources. The neural engineering framework (NEF) is one such method that is supported by Nengo. Most prominently, Nengo and the NEF have been used to engineer the world's largest functional model of the human brain. In addition, as a particularly efficient approach to training neural networks for neuromorphics, the NEF has been ported to several neuromorphic platforms. In this chapter, we discuss the mathematical foundations of the NEF and a number of its extensions and review several recent applications that use Nengo to build models for neuromorphic hardware. We focus in-depth on a particular class of dynamic neural networks, Legendre Memory Units (LMUs), which have demonstrated advantages over state-of-the-art approaches in deep learning with respect to energy efficiency, training time, and accuracy.",
  isbn="978-981-15-2848-4",
  doi="10.1007/978-981-15-2848-4_115-1",
  url="https://doi.org/10.1007/978-981-15-2848-4_115-1",
  pdf="/files/publications/voelker.2020.pdf"
}
