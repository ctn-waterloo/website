@article{stoeckel2022a,
	doi = {10.1088/2634-4386/ac724c},
	url = {https://doi.org/10.1088/2634-4386/ac724c},
	year = 2022,
	month = {may},
	publisher = {{IOP} Publishing},
	author = {Andreas St√∂ckel and Chris Eliasmith},
	title = {Computational properties of multi-compartment {LIF} neurons with passive dendrites},
	journal = {Neuromorphic Computing and Engineering},
	abstract = {Mixed-signal neuromorphic computers often emulate some variant of the LIF neuron model. While, in theory, two-layer networks of these neurons are universal function approximators, single-layer networks consisting of slightly more complex neurons can, at the cost of universality, be more efficient. In this paper, we discuss a family of LIF neurons with passive dendrites. We provide rules that describe how input channels targeting different dendritic compartments interact, and test in how far these interactions can be harnessed in a spiking neural network context. We find that a single layer of two-compartment neurons approximates some functions at smaller errors than similarly sized hidden-layer networks. Single-layer networks with with three compartment neurons can approximate functions such as XOR and four-quadrant multiplication well; adding more compartments only offers small improvements in accuracy. From the perspective of mixed-signal neuromorphic systems, our results suggest that only small modifications to the neuron circuit are necessary to construct more computationally powerful and energy efficient systems that move more computation into the dendritic, analogue domain.}
}
